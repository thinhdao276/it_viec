# ğŸ“– About Content-Based Similarity System

### ğŸ¯ Business Objective
**Requirement 1:** Based on information from companies posted on ITViec, suggest similar companies based on content description.

#### ğŸ“Š System Overview
This Content-Based Similarity system analyzes company information to find similar organizations based on:
- **Company Overview**: Detailed business descriptions
- **Company Industry**: Business sectors and domains  
- **Key Skills**: Technical competencies and technologies

### ğŸ”¬ Implemented Algorithms

| Algorithm | Description | Strengths | Speed | Quality |
|-----------|-------------|-----------|-------|---------|
| **TF-IDF (Scikit-learn)** | Traditional term frequency approach | Fast, reliable, simple | âš¡âš¡âš¡ | â­â­â­ |
| **TF-IDF (Gensim)** | Alternative implementation | Memory efficient, scalable | âš¡âš¡ | â­â­â­ |
| **Doc2Vec** | Document-level vector representations | Context-aware, semantic | âš¡ | â­â­â­â­ |
| **FastText** | Subword information embeddings | Handles rare words, multilingual | âš¡ | â­â­â­â­ |
| **BERT** | Transformer-based understanding | State-of-the-art semantic | âš¡ | â­â­â­â­â­ |

### ğŸ—ï¸ System Architecture
```
ğŸ“Š Data Input â†’ ğŸ§¹ Text Preprocessing â†’ ğŸ”§ Feature Engineering â†’ ğŸ¤– ML Models â†’ ğŸ“ˆ Similarity Computation â†’ ğŸ¯ Recommendations
      â†“                    â†“                     â†“                   â†“                    â†“                    â†“
Companies.xlsx â†’ Clean & Tokenize â†’ TF-IDF/Embeddings â†’ 5 ML Algorithms â†’ Cosine Similarity â†’ Top-K Results
```

### ğŸ“Š Data Requirements
The system works with **3 main columns**:
- **Company Name**: Name of the company
- **Company overview**: Detailed description of the company
- **Our key skills**: Technologies and skills the company specializes in

### ğŸš€ Key Features & Implementation
- **ğŸ¤– Multi-Model Approach**: 5 different ML algorithms for comprehensive analysis
- **ğŸ“Š Beautiful Visualizations**: Interactive dashboards and fancy charts  
- **âš¡ Dual Functionality**: Company-to-company and text-to-company recommendations
- **ğŸ› ï¸ Streamlit Ready**: Production-ready functions for easy integration
- **ğŸ“ˆ Performance Analysis**: Comprehensive model comparison and benchmarking

### ğŸ”§ Core Utils Functions Used

#### ğŸ“ utils/preprocessing.py
- `preprocess_text()` - Advanced text cleaning with Vietnamese support
- `load_and_preprocess_data()` - Intelligent data loading with caching
- `remove_stopwords()` - Multi-language stopword removal

#### ğŸ¤– utils/recommendation_sklearn.py  
- `build_sklearn_tfidf_model()` - TF-IDF vectorization using Scikit-learn
- `get_company_recommendations()` - Company similarity matching
- `get_text_based_recommendations()` - Text query to company search

#### ğŸ§¬ utils/recommendation_gensim.py
- `build_gensim_tfidf_model_and_index()` - Gensim TF-IDF implementation
- `get_gensim_recommendations()` - Gensim-based similarity search
- `build_gensim_dictionary_and_corpus()` - Corpus preparation

#### ğŸ“Š utils/visualization.py
- `create_similarity_chart()` - Interactive similarity visualizations
- `create_wordcloud()` - Beautiful word cloud generation
- `create_industry_chart()` - Industry distribution plots

### ğŸ“‚ Project File Structure
```
ğŸ“ it_viec/
â”œâ”€â”€ ğŸ“„ app.py                           # Main Streamlit application
â”œâ”€â”€ ğŸ“„ app_new_structure.py            # Alternative app structure
â”œâ”€â”€ ğŸ“„ fasttext_corpus.txt             # FastText training corpus
â”œâ”€â”€ ğŸ“„ Overview_Companies_preprocessed.csv # Preprocessed company data
â”œâ”€â”€ ğŸ“„ prompt.md                       # Project prompt and requirements
â”œâ”€â”€ ğŸ“„ README.md                       # Project documentation
â”œâ”€â”€ ğŸ“„ requirements.txt                # Python dependencies
â”œâ”€â”€ ğŸ“„ run.sh                          # Execution script
â”œâ”€â”€ ğŸ“„ thinhdao.typ                    # Additional documentation
â”œâ”€â”€ ğŸ“ __pycache__/                    # Python cache files
â”œâ”€â”€ ğŸ“ archive/                        # Archived versions and experiments
â”‚   â”œâ”€â”€ ğŸ“„ app_archive.py
â”‚   â”œâ”€â”€ ğŸ“„ note.ipynb
â”‚   â”œâ”€â”€ ğŸ“„ Recommendation Modeling - working copy.ipynb
â”‚   â”œâ”€â”€ ğŸ“„ Recommendation Modeling - working.ipynb
â”‚   â”œâ”€â”€ ğŸ“„ Recommendation Modeling V2.ipynb
â”‚   â”œâ”€â”€ ğŸ“„ Recommendation Modeling.ipynb
â”‚   â”œâ”€â”€ ğŸ“„ supervised_truongvanle.ipynb
â”‚   â”œâ”€â”€ ğŸ“„ vietnamese_process.py
â”‚   â”œâ”€â”€ ğŸ“„ yeucau1.ipynb
â”‚   â””â”€â”€ ğŸ“„ yeucau2.ipynb
â”œâ”€â”€ ğŸ“ data/                           # Raw data files
â”‚   â”œâ”€â”€ ğŸ“„ Overview_Companies.xlsx
â”‚   â”œâ”€â”€ ğŸ“„ Overview_Reviews.xlsx
â”‚   â””â”€â”€ ğŸ“„ Reviews.xlsx
â”œâ”€â”€ ğŸ“ models/                         # Trained ML models
â”‚   â”œâ”€â”€ ğŸ“„ CatBoost.pkl
â”‚   â”œâ”€â”€ ğŸ“„ KNN.pkl
â”‚   â”œâ”€â”€ ğŸ“„ LightGBM.pkl
â”‚   â”œâ”€â”€ ğŸ“„ Logistic_Regression.pkl
â”‚   â”œâ”€â”€ ğŸ“„ models_metadata.json
â”‚   â”œâ”€â”€ ğŸ“„ Naive_Bayes.pkl
â”‚   â”œâ”€â”€ ğŸ“„ Random_Forest.pkl
â”‚   â””â”€â”€ ğŸ“„ SVM.pkl
â”œâ”€â”€ ğŸ“ notebooks/                      # Jupyter notebooks for analysis
â”‚   â”œâ”€â”€ ğŸ“„ Content Based Suggestion.ipynb
â”‚   â”œâ”€â”€ ğŸ“„ final_data.xlsx
â”‚   â”œâ”€â”€ ğŸ“„ Project 1 - Exe 1 - Sentiment Analysis.ipynb
â”‚   â”œâ”€â”€ ğŸ“„ Recommendation Modeling Pyspark.ipynb
â”‚   â””â”€â”€ ğŸ“„ Recommendation Modeling.ipynb
â””â”€â”€ ğŸ“ utils/                          # Utility functions and modules
    â”œâ”€â”€ ğŸ“„ __init__.py
    â”œâ”€â”€ ğŸ“„ preprocessing.py            # Data preprocessing utilities
    â”œâ”€â”€ ğŸ“„ recommendation_gensim.py    # Gensim-based recommendations
    â”œâ”€â”€ ğŸ“„ recommendation_sklearn.py   # Scikit-learn based recommendations
    â”œâ”€â”€ ğŸ“„ visualization.py            # Plotting and visualization functions
    â””â”€â”€ ğŸ“ __pycache__/                # Python cache files
```

### âš¡ Performance Optimizations
- **Smart Caching**: Preprocessed data caching for faster loading
- **Lazy Loading**: Models loaded on-demand for better memory usage
- **Parallel Processing**: Multi-core utilization for large datasets
- **Memory Efficiency**: Sparse matrices and optimized data structures
